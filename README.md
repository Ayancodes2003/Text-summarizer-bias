# Text-summarizer-bias

# This research aims to:
## 1. Quantify bias in existing abstractive summarization models:
Develop a framework to 
systematically identify and measure diverse types of bias (e.g., gender, factual accuracy, cultural 
stereotypes) in generated summaries.
## 2. Investigate the impact of bias on downstream tasks: 
Analyze how biased summaries affect 
downstream tasks like information retrieval, decision-making, and user trust.
## 3. Develop techniques for mitigating bias: 
Experiment with different approaches to debias 
summarization models, such as data augmentation, counterfactual training, and fairness-aware 
optimization algorithms.
## 4. Evaluate the effectiveness of mitigation strategies:
Measure the impact of bias mitigation 
techniques on both the fairness and factual accuracy of generated summaries


Paper under progress
